
**Ch·ªß ƒë·ªÅ:** ETL Pipeline (CSV to Postgres)
**Ng√†y:** 28/01/2026

---

## 1. C·ªôt G·ª£i nh·ªõ (Cues) | 2. N·ªôi dung chi ti·∫øt (Notes)

### ‚ùì Big Concept:

**ETL l√† g√¨?**
*(Gi·∫£i th√≠ch ki·ªÉu Feynman)*

> **ETL = Extract - Transform - Load**
> H√£y t∆∞·ªüng t∆∞·ª£ng b·∫°n chuy·ªÉn nh√†:
> 1. **Extract (L·∫•y ƒë·ªì):** L·∫•y ƒë·ªì ƒë·∫°c t·ª´ nh√† c≈© (File CSV tr√™n m·∫°ng).
> 2. **Transform (S·∫Øp x·∫øp):** Ph√¢n lo·∫°i ƒë·ªì d·ªÖ v·ª°, ghi t√™n th√πng, v·ª©t r√°c (S·ª≠a ki·ªÉu d·ªØ li·ªáu, fix datetime).
> 3. **Load (X·∫øp kho):** Ch·∫•t ƒë·ªì v√†o nh√† kho m·ªõi (Postgres Database).
> 
> 

---

### üõ†Ô∏è Tech Stack

**(C√¥ng c·ª• c·∫ßn nh·ªõ)**

* **Jupyter Notebook:** Quy·ªÉn nh√°p ƒëi·ªán t·ª≠. Code d√≤ng n√†o ch·∫°y d√≤ng ƒë√≥, sai s·ª≠a lu√¥n. D√πng ƒë·ªÉ test logic.
* **Pandas:** "Excel b·∫±ng code". D√πng ƒë·ªÉ ƒë·ªçc v√† x·ª≠ l√Ω d·ªØ li·ªáu d·∫°ng b·∫£ng.
* **SQLAlchemy:** Ng∆∞·ªùi phi√™n d·ªãch. Gi√∫p Python n√≥i chuy·ªán ƒë∆∞·ª£c v·ªõi Database.
* **Docker:** C√°i h·ªôp ·∫£o ch·ª©a Database.

---

### ‚ö†Ô∏è Critical Fixes

**(Nh·ªØng l·ªói ƒë√£ g·∫∑p)**

**1. L·ªói Driver SQLAlchemy**

* **V·∫•n ƒë·ªÅ:** SQLAlchemy m·∫∑c ƒë·ªãnh t√¨m `psycopg2` (c≈©), nh∆∞ng m√¨nh c√†i `psycopg` (m·ªõi).
* **Gi·∫£i ph√°p:** S·ª≠a connection string.
* ‚ùå `postgresql://...`
* ‚úÖ `postgresql+psycopg://...`



**2. L·ªói m·∫•t d·ªØ li·ªáu (Docker)**

* **V·∫•n ƒë·ªÅ:** T·∫Øt m√°y -> T·∫Øt Container -> M·∫•t d·ªØ li·ªáu?
* **Gi·∫£i ph√°p:** **Volumes**. D·ªØ li·ªáu kh√¥ng n·∫±m trong Container, n√≥ n·∫±m ·ªü "·ªï c·ª©ng r·ªùi" (Volume).
* **C√∫ ph√°p:** `-v host_path:container_path`

**3. L·ªói "Relation does not exist"**

* **V·∫•n ƒë·ªÅ:** Mount volume sai ch·ªó.
* ‚ùå `/var/lib/postgresql` (Th∆∞ m·ª•c cha)
* ‚úÖ `/var/lib/postgresql/data` (Th∆∞ m·ª•c ch√≠nh x√°c ch·ª©a data c·ªßa Postgres)


* **B√†i h·ªçc:** Sai m·ªôt ly, ƒëi m·ªôt d·∫∑m. Postgres kh√¥ng t√¨m th·∫•y data c≈© -> N√≥ t·∫°o DB m·ªõi tinh -> B·∫£ng bi·∫øn m·∫•t.

---

### üöÄ Performance

**(T·ªëi ∆∞u h√≥a)**

**T·∫°i sao ph·∫£i "Chunking"?**
*(Iterators)*

> **V·∫•n ƒë·ªÅ:** RAM m√°y t√≠nh c√≥ h·∫°n (v√≠ d·ª• 8GB). N·∫øu file CSV n·∫∑ng 10GB -> M√°y treo (Out of Memory).
> **Gi·∫£i ph√°p:** Chia nh·ªè ƒë·ªÉ tr·ªã.
> * D√πng `iterator=True` v√† `chunksize=100000`.
> * Gi·ªëng nh∆∞ u·ªëng bia: Kh√¥ng ai u·ªëng h·∫øt k√©t bia 1 h∆°i. Ph·∫£i u·ªëng t·ª´ng c·ªëc m·ªôt.
> 
> 

**Quy tr√¨nh Ingestion Loop:**

1. **Chunk 1:** `head(0)` ƒë·ªÉ t·∫°o khung b·∫£ng (`replace`). Sau ƒë√≥ n·∫°p d·ªØ li·ªáu.
2. **Chunk 2...n:** `append` (n·ªëi ƒëu√¥i) v√†o b·∫£ng c≈©.
3. **K·∫øt qu·∫£:** 1 tri·ªáu d√≤ng ƒë∆∞·ª£c n·∫°p m∆∞·ª£t m√†, RAM kh√¥ng b·ªã qu√° t·∫£i.

---

### üíª Code Snippets

**(Copy-paste cheatsheet)**

**1. Connect DB:**

```python
engine = create_engine('postgresql+psycopg://root:root@localhost:5432/ny_taxi')
engine.connect()

```

**2. Chunking Iterator:**

```python
df_iter = pd.read_csv(url, iterator=True, chunksize=100000)

```

**3. The Loop:**

```python
for chunk in df_iter:
    chunk.to_sql(name='table_name', con=engine, if_exists='append')

```

**4. Fix Docker Volume:**

```bash
docker run ... -v ny_taxi_postgres_data:/var/lib/postgresql/data ...

```

---

## 3. T·ªïng k·∫øt (Summary)

H√¥m nay m√¨nh ƒë√£ h·ªçc c√°ch x√¢y d·ª±ng m·ªôt **Data Pipeline ƒë∆°n gi·∫£n**:

1. Kh√¥ng t·∫£i file CSV v·ªÅ m√°y local, m√† stream tr·ª±c ti·∫øp t·ª´ m·∫°ng v√†o RAM.
2. D√πng **Pandas Chunking** ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu l·ªõn h∆°n dung l∆∞·ª£ng RAM cho ph√©p.
3. Hi·ªÉu s√¢u v·ªÅ **Docker Volumes**: Container l√† t·∫°m th·ªùi (ephemeral), Volume l√† vƒ©nh c·ª≠u (persistent). N·∫øu m·∫•t d·ªØ li·ªáu, ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n mount (`/data`).
4. Debug th√†nh c√¥ng c√°c l·ªói k·∫øt n·ªëi ph·ªï bi·∫øn gi·ªØa Python v√† Postgres.

